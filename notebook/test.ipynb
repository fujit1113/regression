{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 自作パッケージのインポート\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from mypoc import *\n",
    "\n",
    "PATH_DATA: str = \"../input\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../input\") / \"data.pkl\"\n",
    "\n",
    "Splitter.split_data(path, \"trial\", \"regression\", target=\"visitors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: preds, Expected type: <class 'numpy.ndarray'>\n",
      "Expected return type: typing.Tuple[numpy.ndarray, numpy.ndarray]\n",
      "Parameter: train_data, Expected type: <class 'lightgbm.basic.Dataset'>\n",
      "Expected return type: typing.Tuple[numpy.ndarray, numpy.ndarray]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\validator.py:194: UserWarning: The model folder for the run 'trial' already exists. New models will be added to this folder.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def my_make_loss(df: pd.DataFrame):\n",
    "    latest_date = df[\"visit_date\"].max()\n",
    "    days_diff = (latest_date - df[\"visit_date\"]).dt.total_seconds() / (24 * 60 * 60)\n",
    "    weight = 0.99**days_diff\n",
    "\n",
    "    def loss_func(\n",
    "        preds: np.ndarray,\n",
    "        train_data: lgb.Dataset,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        y = train_data.get_label()\n",
    "        grad = weight * (preds - y)\n",
    "        hess = weight\n",
    "        return grad, hess\n",
    "\n",
    "    return loss_func\n",
    "\n",
    "\n",
    "run_name = \"trial\"\n",
    "task = \"regression\"\n",
    "target = \"visitors\"\n",
    "features = [\n",
    "    \"is_Monday\",\n",
    "    \"is_Tuesday\",\n",
    "    \"is_Wednesday\",\n",
    "    \"is_Thursday\",\n",
    "    \"is_Friday\",\n",
    "    \"is_Saturday\",\n",
    "    \"is_Sunday\",\n",
    "    \"is_holiday\",\n",
    "    \"visitors_last_week\",\n",
    "    \"is_holiday_last_week\",\n",
    "    \"visitors_2_week_ago\",\n",
    "    \"is_holiday_2_week_ago\",\n",
    "    \"visitors_3_week_ago\",\n",
    "    \"is_holiday_3_week_ago\",\n",
    "    \"is_holiday_2_week_ago\",\n",
    "    \"visitors_4_week_ago\",\n",
    "    \"is_holiday_4_week_ago\",\n",
    "]\n",
    "recipes = [\n",
    "    {\"model_class\": ModelLGB, \"model_name\": \"lgb\", \"make_loss_func\": my_make_loss}\n",
    "]\n",
    "additions = [\"visit_date\"]\n",
    "\n",
    "var = Validator(run_name, task, target, features, recipes, additions)\n",
    "var.validate_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mypoc.validator.Validator object at 0x0000022A602F9720>\n",
       "run_name: trial\n",
       "task: regression\n",
       "target: visitors\n",
       "features: ['is_Monday', 'is_Tuesday', 'is_Wednesday', 'is_Thursday', 'is_Friday', 'is_Saturday', 'is_Sunday', 'is_holiday', 'visitors_last_week', 'is_holiday_last_week', 'visitors_2_week_ago', 'is_holiday_2_week_ago', 'visitors_3_week_ago', 'is_holiday_3_week_ago', 'is_holiday_2_week_ago', 'visitors_4_week_ago', 'is_holiday_4_week_ago']\n",
       "recipes: [{'model_class': <class 'mypoc.model_lgb.ModelLGB'>, 'model_name': 'lgb', 'fixed_params': None, 'make_loss_func': <function my_make_loss at 0x0000022A602F5BD0>, 'make_eval_func': None}]\n",
       "additions: ['visit_date']\n",
       "n_fold: 5\n",
       "description: \n",
       "_is_available: True\n",
       "models: [<mypoc.model_lgb.ModelLGB object at 0x0000022A2EB23BE0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 23:26:41,257 - general - INFO - [2023-06-07 23:26:41] - trial - start training cv\n",
      "Processing folds:   0%|          | 0/5 [00:00<?, ?it/s]2023-06-07 23:26:41,263 - general - INFO - [2023-06-07 23:26:41] - trial fold 0 - start training\n",
      "\u001b[32m[I 2023-06-07 23:26:41,275]\u001b[0m A new study created in memory with name: no-name-7cbdb74a-bc3d-4aeb-94a3-fc71cfd7422e\u001b[0m\n",
      "\u001b[33m[W 2023-06-07 23:26:41,277]\u001b[0m Trial 0 failed with parameters: {} because of the following error: TypeError(\"argument of type 'NoneType' is not iterable\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 192, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 268, in _objective\n",
      "    model.set_params(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 81, in set_params\n",
      "    if param not in self.fixed_params:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "\u001b[33m[W 2023-06-07 23:26:41,281]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "2023-06-07 23:26:41,281 - general - INFO - [2023-06-07 23:26:41] - trial fold 0 - end training\n",
      "2023-06-07 23:26:41,282 - general - INFO - [2023-06-07 23:26:41] - trial fold 1 - start training\n",
      "\u001b[32m[I 2023-06-07 23:26:41,292]\u001b[0m A new study created in memory with name: no-name-f30e0a28-d51d-493f-a7b4-9a4dd7a872f8\u001b[0m\n",
      "\u001b[33m[W 2023-06-07 23:26:41,294]\u001b[0m Trial 0 failed with parameters: {} because of the following error: TypeError(\"argument of type 'NoneType' is not iterable\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 192, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 268, in _objective\n",
      "    model.set_params(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 81, in set_params\n",
      "    if param not in self.fixed_params:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "\u001b[33m[W 2023-06-07 23:26:41,295]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "2023-06-07 23:26:41,296 - general - INFO - [2023-06-07 23:26:41] - trial fold 1 - end training\n",
      "2023-06-07 23:26:41,296 - general - INFO - [2023-06-07 23:26:41] - trial fold 2 - start training\n",
      "\u001b[32m[I 2023-06-07 23:26:41,307]\u001b[0m A new study created in memory with name: no-name-6a28a879-99c2-42da-8332-29312fde1336\u001b[0m\n",
      "\u001b[33m[W 2023-06-07 23:26:41,309]\u001b[0m Trial 0 failed with parameters: {} because of the following error: TypeError(\"argument of type 'NoneType' is not iterable\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 192, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 268, in _objective\n",
      "    model.set_params(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 81, in set_params\n",
      "    if param not in self.fixed_params:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "\u001b[33m[W 2023-06-07 23:26:41,310]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "2023-06-07 23:26:41,311 - general - INFO - [2023-06-07 23:26:41] - trial fold 2 - end training\n",
      "2023-06-07 23:26:41,312 - general - INFO - [2023-06-07 23:26:41] - trial fold 3 - start training\n",
      "\u001b[32m[I 2023-06-07 23:26:41,324]\u001b[0m A new study created in memory with name: no-name-5de97f86-5cf0-46de-8494-ac4b93e5cec6\u001b[0m\n",
      "\u001b[33m[W 2023-06-07 23:26:41,326]\u001b[0m Trial 0 failed with parameters: {} because of the following error: TypeError(\"argument of type 'NoneType' is not iterable\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 192, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 268, in _objective\n",
      "    model.set_params(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 81, in set_params\n",
      "    if param not in self.fixed_params:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "\u001b[33m[W 2023-06-07 23:26:41,328]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "2023-06-07 23:26:41,328 - general - INFO - [2023-06-07 23:26:41] - trial fold 3 - end training\n",
      "2023-06-07 23:26:41,329 - general - INFO - [2023-06-07 23:26:41] - trial fold 4 - start training\n",
      "\u001b[32m[I 2023-06-07 23:26:41,341]\u001b[0m A new study created in memory with name: no-name-435c09d9-a411-4652-aa38-a3a433c65f28\u001b[0m\n",
      "\u001b[33m[W 2023-06-07 23:26:41,343]\u001b[0m Trial 0 failed with parameters: {} because of the following error: TypeError(\"argument of type 'NoneType' is not iterable\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 192, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 268, in _objective\n",
      "    model.set_params(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 81, in set_params\n",
      "    if param not in self.fixed_params:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "\u001b[33m[W 2023-06-07 23:26:41,344]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "2023-06-07 23:26:41,344 - general - INFO - [2023-06-07 23:26:41] - trial fold 4 - end training\n",
      "Processing folds: 100%|██████████| 5/5 [00:00<00:00, 61.05it/s]\n",
      "2023-06-07 23:26:41,346 - general - INFO - [2023-06-07 23:26:41] - trial - end training cv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization for model 0 failed with exception:\n",
      "argument of type 'NoneType' is not iterable\n",
      "Optimization for model 0 failed with exception:\n",
      "argument of type 'NoneType' is not iterable\n",
      "Optimization for model 0 failed with exception:\n",
      "argument of type 'NoneType' is not iterable\n",
      "Optimization for model 0 failed with exception:\n",
      "argument of type 'NoneType' is not iterable\n",
      "Optimization for model 0 failed with exception:\n",
      "argument of type 'NoneType' is not iterable\n"
     ]
    }
   ],
   "source": [
    "rn = Runner(var)\n",
    "rn.run_train_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_399904bdb7685ca0</td>\n",
       "      <td>18717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_f26f36ec4dc5adb0</td>\n",
       "      <td>18577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_e55abd740f93ecc4</td>\n",
       "      <td>18101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_99157b6163835eec</td>\n",
       "      <td>18097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_5c817ef28f236bdf</td>\n",
       "      <td>18009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visitors\n",
       "0  air_399904bdb7685ca0     18717\n",
       "1  air_f26f36ec4dc5adb0     18577\n",
       "2  air_e55abd740f93ecc4     18101\n",
       "3  air_99157b6163835eec     18097\n",
       "4  air_5c817ef28f236bdf     18009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# air_visit_data.csv を pandas の DataFrame の形式で読み込む\n",
    "air_visit = pd.read_csv(os.path.join(PATH_DATA, \"air_visit_data.csv\"))\n",
    "\n",
    "# 店舗ごとに総来店客数を算出\n",
    "visitor_counts_by_store = (\n",
    "    air_visit.groupby(\"air_store_id\")[\"visitors\"].sum().reset_index()\n",
    ")\n",
    "\n",
    "# 総来店客数が多い上位５店舗だけ表示\n",
    "visitor_counts_by_store.sort_values(\"visitors\", ascending=False).reset_index(\n",
    "    drop=True\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.asia import Japan\n",
    "\n",
    "# 　店舗 air_399904bdb7685ca0 の日ごとの来店客数を全量格納\n",
    "air_visit_max = air_visit.query('air_store_id == \"air_399904bdb7685ca0\"').reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "air_visit_max[\"visit_date\"] = pd.to_datetime(air_visit_max[\"visit_date\"])\n",
    "\n",
    "air_visit_max[\"is\"] = air_visit_max[\"visit_date\"].dt.dayofweek\n",
    "\n",
    "# 必要に応じて0-6の整数を文字列の曜日に変換\n",
    "days = {\n",
    "    0: \"Monday\",\n",
    "    1: \"Tuesday\",\n",
    "    2: \"Wednesday\",\n",
    "    3: \"Thursday\",\n",
    "    4: \"Friday\",\n",
    "    5: \"Saturday\",\n",
    "    6: \"Sunday\",\n",
    "}\n",
    "air_visit_max[\"is\"] = air_visit_max[\"is\"].apply(lambda x: days[x])\n",
    "\n",
    "cal = Japan()\n",
    "\n",
    "# 'day_of_week'カラムが休日であるかどうかを示す新しいカラムを作成\n",
    "air_visit_max[\"is_holiday\"] = air_visit_max[\"visit_date\"].apply(\n",
    "    lambda x: int(cal.is_holiday(x))\n",
    ")\n",
    "\n",
    "air_visit_max = pd.get_dummies(air_visit_max, columns=[\"is\"])\n",
    "\n",
    "air_visit_max[\"visitors_last_week\"] = air_visit_max[\"visitors\"].shift(7)\n",
    "air_visit_max[\"is_holiday_last_week\"] = air_visit_max[\"is_holiday\"].shift(7)\n",
    "air_visit_max[\"visitors_2_week_ago\"] = air_visit_max[\"visitors\"].shift(14)\n",
    "air_visit_max[\"is_holiday_2_week_ago\"] = air_visit_max[\"is_holiday\"].shift(14)\n",
    "air_visit_max[\"visitors_3_week_ago\"] = air_visit_max[\"visitors\"].shift(21)\n",
    "air_visit_max[\"is_holiday_3_week_ago\"] = air_visit_max[\"is_holiday\"].shift(21)\n",
    "air_visit_max[\"visitors_4_week_ago\"] = air_visit_max[\"visitors\"].shift(28)\n",
    "air_visit_max[\"is_holiday_4_week_ago\"] = air_visit_max[\"is_holiday\"].shift(28)\n",
    "air_visit_max.head(50)\n",
    "\n",
    "column_order = [\n",
    "    \"visit_date\",\n",
    "    \"visitors\",\n",
    "    \"is_Monday\",\n",
    "    \"is_Tuesday\",\n",
    "    \"is_Wednesday\",\n",
    "    \"is_Thursday\",\n",
    "    \"is_Friday\",\n",
    "    \"is_Saturday\",\n",
    "    \"is_Sunday\",\n",
    "    \"is_holiday\",\n",
    "    \"visitors_last_week\",\n",
    "    \"is_holiday_last_week\",\n",
    "    \"visitors_2_week_ago\",\n",
    "    \"is_holiday_2_week_ago\",\n",
    "    \"visitors_3_week_ago\",\n",
    "    \"is_holiday_3_week_ago\",\n",
    "    \"is_holiday_2_week_ago\",\n",
    "    \"visitors_4_week_ago\",\n",
    "    \"is_holiday_4_week_ago\",\n",
    "]\n",
    "df = air_visit_max[column_order]\n",
    "\n",
    "# df.head(30)\n",
    "df = df[df[\"visit_date\"] > \"2016-02-01\"]\n",
    "\n",
    "df.to_pickle(os.path.join(PATH_DATA, \"data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>is_Monday</th>\n",
       "      <th>is_Tuesday</th>\n",
       "      <th>is_Wednesday</th>\n",
       "      <th>is_Thursday</th>\n",
       "      <th>is_Friday</th>\n",
       "      <th>is_Saturday</th>\n",
       "      <th>is_Sunday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>visitors_last_week</th>\n",
       "      <th>is_holiday_last_week</th>\n",
       "      <th>visitors_2_week_ago</th>\n",
       "      <th>is_holiday_2_week_ago</th>\n",
       "      <th>visitors_3_week_ago</th>\n",
       "      <th>is_holiday_3_week_ago</th>\n",
       "      <th>is_holiday_2_week_ago</th>\n",
       "      <th>visitors_4_week_ago</th>\n",
       "      <th>is_holiday_4_week_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016-02-06</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    visit_date  visitors  is_Monday  is_Tuesday  is_Wednesday  is_Thursday  \\\n",
       "28  2016-02-02        21          0           1             0            0   \n",
       "29  2016-02-03        26          0           0             1            0   \n",
       "30  2016-02-04        53          0           0             0            1   \n",
       "31  2016-02-05        49          0           0             0            0   \n",
       "32  2016-02-06        63          0           0             0            0   \n",
       "..         ...       ...        ...         ...           ...          ...   \n",
       "452 2017-04-18        31          0           1             0            0   \n",
       "453 2017-04-19        17          0           0             1            0   \n",
       "454 2017-04-20        24          0           0             0            1   \n",
       "455 2017-04-21        20          0           0             0            0   \n",
       "456 2017-04-22        56          0           0             0            0   \n",
       "\n",
       "     is_Friday  is_Saturday  is_Sunday  is_holiday  visitors_last_week  \\\n",
       "28           0            0          0           0                52.0   \n",
       "29           0            0          0           0                48.0   \n",
       "30           0            0          0           0                49.0   \n",
       "31           1            0          0           0                59.0   \n",
       "32           0            1          0           0                18.0   \n",
       "..         ...          ...        ...         ...                 ...   \n",
       "452          0            0          0           0                 4.0   \n",
       "453          0            0          0           0                23.0   \n",
       "454          0            0          0           0                16.0   \n",
       "455          1            0          0           0                44.0   \n",
       "456          0            1          0           0                50.0   \n",
       "\n",
       "     is_holiday_last_week  visitors_2_week_ago  is_holiday_2_week_ago  \\\n",
       "28                    0.0                 23.0                    0.0   \n",
       "29                    0.0                 34.0                    0.0   \n",
       "30                    0.0                 43.0                    0.0   \n",
       "31                    0.0                 93.0                    0.0   \n",
       "32                    0.0                123.0                    0.0   \n",
       "..                    ...                  ...                    ...   \n",
       "452                   0.0                 17.0                    0.0   \n",
       "453                   0.0                 25.0                    0.0   \n",
       "454                   0.0                 15.0                    0.0   \n",
       "455                   0.0                  7.0                    0.0   \n",
       "456                   0.0                 44.0                    0.0   \n",
       "\n",
       "     visitors_3_week_ago  is_holiday_3_week_ago  is_holiday_2_week_ago  \\\n",
       "28                  43.0                    0.0                    0.0   \n",
       "29                  20.0                    0.0                    0.0   \n",
       "30                   4.0                    0.0                    0.0   \n",
       "31                 116.0                    0.0                    0.0   \n",
       "32                  51.0                    0.0                    0.0   \n",
       "..                   ...                    ...                    ...   \n",
       "452                 16.0                    0.0                    0.0   \n",
       "453                 34.0                    0.0                    0.0   \n",
       "454                 61.0                    0.0                    0.0   \n",
       "455                 22.0                    0.0                    0.0   \n",
       "456                 45.0                    0.0                    0.0   \n",
       "\n",
       "     visitors_4_week_ago  is_holiday_4_week_ago  \n",
       "28                   4.0                    0.0  \n",
       "29                  15.0                    0.0  \n",
       "30                  26.0                    0.0  \n",
       "31                  75.0                    0.0  \n",
       "32                  91.0                    0.0  \n",
       "..                   ...                    ...  \n",
       "452                 51.0                    0.0  \n",
       "453                 27.0                    1.0  \n",
       "454                 16.0                    0.0  \n",
       "455                 47.0                    0.0  \n",
       "456                 11.0                    0.0  \n",
       "\n",
       "[429 rows x 19 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.read_pickle(os.path.join(PATH_DATA, \"data.pkl\"))\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Subscripted generics cannot be used with class and instance checks",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m Callable[[pd\u001b[39m.\u001b[39mDataFrame], Callable]\n\u001b[0;32m     17\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mssa\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 18\u001b[0m check_param_type(enclosure, \u001b[39m\"\u001b[39;49m\u001b[39malpha\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mtype\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m, in \u001b[0;36mcheck_param_type\u001b[1;34m(param, name, expected_type)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_param_type\u001b[39m(param, name, expected_type):\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39;49m(param, expected_type):\n\u001b[0;32m      5\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m must be of type \u001b[39m\u001b[39m{\u001b[39;00mexpected_type\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\typing.py:994\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__instancecheck__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mself\u001b[39m, obj):\n\u001b[1;32m--> 994\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__subclasscheck__\u001b[39;49m(\u001b[39mtype\u001b[39;49m(obj))\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\typing.py:997\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__subclasscheck__\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__subclasscheck__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mcls\u001b[39m):\n\u001b[1;32m--> 997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSubscripted generics cannot be used with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m class and instance checks\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Subscripted generics cannot be used with class and instance checks"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Union\n",
    "\n",
    "def check_param_type(param, name, expected_type):\n",
    "    if not isinstance(param, expected_type):\n",
    "        raise TypeError(f\"Parameter '{name}' must be of type {expected_type}.\")\n",
    "\n",
    "def enclosure(df: pd.DataFrame):\n",
    "    def closure(val: float):\n",
    "        pass\n",
    "    \n",
    "    return closure``\n",
    "\n",
    "        \n",
    "type = Callable[[pd.DataFrame], Callable]\n",
    "b\n",
    "check_param_type(enclosure, \"alpha\", type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: df, Expected type: <class 'pandas.core.frame.DataFrame'>\n",
      "Expected return type: typing.Callable[[numpy.ndarray, lightgbm.basic.Dataset], typing.Tuple[numpy.ndarray, numpy.ndarray]]\n"
     ]
    }
   ],
   "source": [
    "from inspect import signature, Parameter\n",
    "import lightgbm as lgb\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def enclosure(\n",
    "    df: pd.DataFrame,\n",
    ") -> Callable[[np.ndarray, lgb.Dataset], Tuple[np.ndarray, np.ndarray]]:\n",
    "    def closure(\n",
    "        pred: np.ndarray, train_data: lgb.Dataset\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return a, b\n",
    "\n",
    "    return closure\n",
    "\n",
    "\n",
    "sig = signature(enclosure)\n",
    "params = sig.parameters\n",
    "\n",
    "\n",
    "for param in sig.parameters.values():\n",
    "    print(f\"Parameter: {param.name}, Expected type: {param.annotation}\")\n",
    "    print(f\"Expected return type: {sig.return_annotation}\")\n",
    "# if len(params) != 2:\n",
    "#     raise ValueError(\n",
    "#         \"The custom loss function must have exactly two arguments\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnerParams\n",
    "from typing import Callable\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def loss_for_LGB_example(\n",
    "    X: pd.DataFrame,\n",
    "    time_col: str,\n",
    "    r: float,\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    LightGBM の損失関数のエンクロージャ。\n",
    "\n",
    "    最新日時との差分から、重みを計算する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        データフレーム\n",
    "\n",
    "    time_col : str\n",
    "        タイムスタンプのカラム名\n",
    "\n",
    "    r : float\n",
    "        忘却率\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Callable\n",
    "    \"\"\"\n",
    "    # 忘却率に基づいた重みを設定する\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    latest_time = df[time_col].max()\n",
    "    df[\"time_difference\"] = latest_time - df[time_col]\n",
    "    weight = r ** df[\"time_difference\"]\n",
    "\n",
    "    def loss_func(preds: np.ndarray, train_data: lgb.Dataset):\n",
    "        \"\"\"\n",
    "        LightGBM の損失関数\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        preds : np.ndarray\n",
    "            予測値\n",
    "\n",
    "        train_data : lgb.Dataset\n",
    "            実測値\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple(np.ndarray, np.ndarray)\n",
    "        \"\"\"\n",
    "        y = train_data.get_label()\n",
    "        grad = weight * (preds - y)\n",
    "        hess = weight * np.ones(len(y))\n",
    "\n",
    "        return grad, hess\n",
    "\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    \"run_name\": \"first\",\n",
    "    \"task\": \"regression\",\n",
    "    \"target\": \"target\",\n",
    "    \"features\": list(X.columns),\n",
    "    \"model_recipes\": model_recipes,\n",
    "    \"model_classes\": [ModelLGB],\n",
    "    \"fixed_params\": [{}],\n",
    "    \"make_loss_funcs\": [loss_for_LGB],\n",
    "    \"make_eval_funcs\": [loss_for_LGB],\n",
    "    \"description\": \"trial\",\n",
    "}\n",
    "rp = RunnerParams(**params_dict)\n",
    "\n",
    "# len([loss_for_LGB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSplitter.split_data(\"data.pkl\", \"first\", \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-30 17:26:54] - first - start training cv\n",
      "Processing folds:   0%|          | 0/5 [00:00<?, ?it/s][2023-05-30 17:26:54] - first fold 0 - start training\n",
      "\u001b[32m[I 2023-05-30 17:26:54,758]\u001b[0m A new study created in memory with name: no-name-1e47e93d-9d71-4204-86bf-0b5f615c2bf4\u001b[0m\n",
      "\u001b[33m[W 2023-05-30 17:26:54,767]\u001b[0m Trial 0 failed with parameters: {'reg_alpha': 0.01008701813668789, 'reg_lambda': 0.0005735101632254607, 'num_leaves': 5, 'colsample_bytree': 0.8070734651702838, 'subsample': 0.627175178502248, 'subsample_freq': 0, 'min_child_samples': 5} because of the following error: ValueError('not enough values to unpack (expected 3, got 2)').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 230, in <lambda>\n",
      "    lambda trial: self._objective(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py\", line 165, in _objective\n",
      "    model.train(tr_x, tr_y, loss_func_tr, va_x, va_y, loss_func_va)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py\", line 56, in train\n",
      "    self.model = lgb.train(\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\engine.py\", line 299, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py\", line 3271, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py\", line 3272, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"c:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py\", line 3814, in __inner_eval\n",
      "    eval_name, val, is_higher_better = feval_ret\n",
      "ValueError: not enough values to unpack (expected 3, got 2)\n",
      "\u001b[33m[W 2023-05-30 17:26:54,773]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "Processing folds:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 514\n",
      "[LightGBM] [Info] Number of data points in the train set: 282, number of used features: 10\n",
      "[LightGBM] [Warning] Using self-defined objective function\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# xgboostによる学習・予測\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rr \u001b[39m=\u001b[39m Runner(rp)\n\u001b[1;32m----> 3\u001b[0m rr\u001b[39m.\u001b[39;49mrun_train_cv()\n\u001b[0;32m      4\u001b[0m \u001b[39m# runner = Runner('xgb1', ModelLGB, features, params_xgb)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# runner.run_train_cv()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# runner.run_predict_cv()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Submission.create_submission('xgb1')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py:283\u001b[0m, in \u001b[0;36mRunner.run_train_cv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39mfor\u001b[39;00m i_fold \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_fold), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing folds\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_name\u001b[39m}\u001b[39;00m\u001b[39m fold \u001b[39m\u001b[39m{\u001b[39;00mi_fold\u001b[39m}\u001b[39;00m\u001b[39m - start training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 283\u001b[0m     df\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_fold(i_fold))\n\u001b[0;32m    284\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_name\u001b[39m}\u001b[39;00m\u001b[39m fold \u001b[39m\u001b[39m{\u001b[39;00mi_fold\u001b[39m}\u001b[39;00m\u001b[39m - end training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    286\u001b[0m \u001b[39m# クロスバリデーション終了\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py:87\u001b[0m, in \u001b[0;36mRunner._train_fold\u001b[1;34m(self, i_fold, n_trials)\u001b[0m\n\u001b[0;32m     84\u001b[0m     tr_x, tr_y \u001b[39m=\u001b[39m train_x\u001b[39m.\u001b[39miloc[tr_idx], train_y\u001b[39m.\u001b[39miloc[tr_idx]\n\u001b[0;32m     85\u001b[0m     va_x, va_y \u001b[39m=\u001b[39m train_x\u001b[39m.\u001b[39miloc[va_idx], train_y\u001b[39m.\u001b[39miloc[va_idx]\n\u001b[1;32m---> 87\u001b[0m     models, loss_vals_tr, loss_vals_va, evals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_models(\n\u001b[0;32m     88\u001b[0m         i_fold, tr_x, tr_y, va_x, va_y, n_trials\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[39m# 全学習データで学習\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     models, loss_vals_tr, loss_vals_va, evals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_models(\n\u001b[0;32m     94\u001b[0m         i_fold, train_x, train_y, n_trials\n\u001b[0;32m     95\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py:229\u001b[0m, in \u001b[0;36mRunner._build_models\u001b[1;34m(self, i_fold, tr_x, tr_y, va_x, va_y, n_trials)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39m# Optuna で最適なハイパーパラメータ探索\u001b[39;00m\n\u001b[0;32m    228\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 229\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m    230\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objective(\n\u001b[0;32m    231\u001b[0m         trial,\n\u001b[0;32m    232\u001b[0m         fixed_param,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m    234\u001b[0m         tr_x,\n\u001b[0;32m    235\u001b[0m         tr_y,\n\u001b[0;32m    236\u001b[0m         loss_func_tr,\n\u001b[0;32m    237\u001b[0m         va_x,\n\u001b[0;32m    238\u001b[0m         va_y,\n\u001b[0;32m    239\u001b[0m         loss_func_va,\n\u001b[0;32m    240\u001b[0m     ),\n\u001b[0;32m    241\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    242\u001b[0m )\n\u001b[0;32m    244\u001b[0m \u001b[39m# 最適なパラメータでモデルを作成・学習\u001b[39;00m\n\u001b[0;32m    245\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    246\u001b[0m     model_name_fold, {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfixed_param, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstudy\u001b[39m.\u001b[39mbest_params}, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py:230\u001b[0m, in \u001b[0;36mRunner._build_models.<locals>.<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39m# Optuna で最適なハイパーパラメータ探索\u001b[39;00m\n\u001b[0;32m    228\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    229\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objective(\n\u001b[0;32m    231\u001b[0m         trial,\n\u001b[0;32m    232\u001b[0m         fixed_param,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m    234\u001b[0m         tr_x,\n\u001b[0;32m    235\u001b[0m         tr_y,\n\u001b[0;32m    236\u001b[0m         loss_func_tr,\n\u001b[0;32m    237\u001b[0m         va_x,\n\u001b[0;32m    238\u001b[0m         va_y,\n\u001b[0;32m    239\u001b[0m         loss_func_va,\n\u001b[0;32m    240\u001b[0m     ),\n\u001b[0;32m    241\u001b[0m     n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[0;32m    242\u001b[0m )\n\u001b[0;32m    244\u001b[0m \u001b[39m# 最適なパラメータでモデルを作成・学習\u001b[39;00m\n\u001b[0;32m    245\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    246\u001b[0m     model_name_fold, {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfixed_param, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstudy\u001b[39m.\u001b[39mbest_params}, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\runner.py:165\u001b[0m, in \u001b[0;36mRunner._objective\u001b[1;34m(self, trial, fixed_params, model_cls, tr_x, tr_y, loss_func_tr, va_x, va_y, loss_func_va)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m# モデルの作成と学習\u001b[39;00m\n\u001b[0;32m    160\u001b[0m model \u001b[39m=\u001b[39m model_cls(\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrial\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    162\u001b[0m     params,\n\u001b[0;32m    163\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask,\n\u001b[0;32m    164\u001b[0m )\n\u001b[1;32m--> 165\u001b[0m model\u001b[39m.\u001b[39;49mtrain(tr_x, tr_y, loss_func_tr, va_x, va_y, loss_func_va)\n\u001b[0;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m loss_func_va(va_y\u001b[39m.\u001b[39mvalues, model\u001b[39m.\u001b[39mpredict(va_x))\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\Documents\\GitHub\\regression\\notebook\\..\\mypoc\\model_lgb.py:56\u001b[0m, in \u001b[0;36mModelLGB.train\u001b[1;34m(self, tr_x, tr_y, loss_func_tr, va_x, va_y, loss_func_va)\u001b[0m\n\u001b[0;32m     53\u001b[0m     dvalid \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(va_x, label\u001b[39m=\u001b[39mva_y)\n\u001b[0;32m     55\u001b[0m     \u001b[39m# 注意: feval は大きい値の方が、望ましい\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m     57\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams,\n\u001b[0;32m     58\u001b[0m         dtrain,\n\u001b[0;32m     59\u001b[0m         valid_sets\u001b[39m=\u001b[39;49mdvalid,\n\u001b[0;32m     60\u001b[0m         fobj\u001b[39m=\u001b[39;49mloss_func_tr,\n\u001b[0;32m     61\u001b[0m         feval\u001b[39m=\u001b[39;49mloss_func_va,  \u001b[39m# 要修正\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mtrain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, dtrain, fobj\u001b[39m=\u001b[39mloss_func_tr)\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\engine.py:299\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    298\u001b[0m         evaluation_result_list\u001b[39m.\u001b[39mextend(booster\u001b[39m.\u001b[39meval_train(feval))\n\u001b[1;32m--> 299\u001b[0m     evaluation_result_list\u001b[39m.\u001b[39mextend(booster\u001b[39m.\u001b[39;49meval_valid(feval))\n\u001b[0;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_after_iter:\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py:3271\u001b[0m, in \u001b[0;36mBooster.eval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   3240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_valid\u001b[39m(\u001b[39mself\u001b[39m, feval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   3242\u001b[0m \n\u001b[0;32m   3243\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3269\u001b[0m \u001b[39m        List with evaluation results.\u001b[39;00m\n\u001b[0;32m   3270\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3271\u001b[0m     \u001b[39mreturn\u001b[39;00m [item \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)\n\u001b[0;32m   3272\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__inner_eval(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_valid_sets[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m], i, feval)]\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py:3272\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_valid\u001b[39m(\u001b[39mself\u001b[39m, feval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   3242\u001b[0m \n\u001b[0;32m   3243\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3269\u001b[0m \u001b[39m        List with evaluation results.\u001b[39;00m\n\u001b[0;32m   3270\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3271\u001b[0m     \u001b[39mreturn\u001b[39;00m [item \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)\n\u001b[1;32m-> 3272\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__inner_eval(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname_valid_sets[i \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m], i, feval)]\n",
      "File \u001b[1;32mc:\\Users\\sumitaka.fujita\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\lightgbm\\basic.py:3814\u001b[0m, in \u001b[0;36mBooster.__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   3812\u001b[0m                 ret\u001b[39m.\u001b[39mappend((data_name, eval_name, val, is_higher_better))\n\u001b[0;32m   3813\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3814\u001b[0m             eval_name, val, is_higher_better \u001b[39m=\u001b[39m feval_ret\n\u001b[0;32m   3815\u001b[0m             ret\u001b[39m.\u001b[39mappend((data_name, eval_name, val, is_higher_better))\n\u001b[0;32m   3816\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# xgboostによる学習・予測\n",
    "rr = Runner(rp)\n",
    "rr.run_train_cv()\n",
    "# runner = Runner('xgb1', ModelLGB, features, params_xgb)\n",
    "# runner.run_train_cv()\n",
    "# runner.run_predict_cv()\n",
    "# Submission.create_submission('xgb1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (461170021.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    **params\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "            \"n_splits\": 5,\n",
    "            \"shuffle\": True,\n",
    "            \"random_state\": 10,\n",
    "        }\n",
    "**params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
